# é«˜çº§æœç´¢æœºåˆ¶å®éªŒ - å¿«é€Ÿå¯åŠ¨æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—å¸®åŠ©ä½ å¿«é€Ÿè¿è¡Œå®Œæ•´çš„æ¶ˆèå®éªŒå’ŒåŸºå‡†æµ‹è¯•,éªŒè¯frontier-basedæ¢ç´¢å’ŒååŒæœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚

---

## å‰ç½®å‡†å¤‡

### 1. æ£€æŸ¥ä»£ç æäº¤

```bash
# ç¡®è®¤åœ¨reg_searchåˆ†æ”¯
git branch

# æŸ¥çœ‹æœ€è¿‘æäº¤(åº”è¯¥çœ‹åˆ°4å‘¨çš„å·¥ä½œ)
git log --oneline -4

# é¢„æœŸè¾“å‡º:
# 95f4b49 feat: implement ablation study and benchmark framework (Week 4)
# 8133707 feat: implement comprehensive evaluation metrics system (Week 3)
# 8dc62da feat: implement coordination mechanisms for multi-agent search (Week 2)
# 689e615 feat: implement frontier-based intrinsic reward mechanism (Week 1)
```

### 2. å®‰è£…ä¾èµ–

```bash
# æ ¸å¿ƒä¾èµ–
pip install numpy pandas scipy pyyaml

# å¯è§†åŒ–(æ¨è)
pip install matplotlib seaborn

# TensorBoardæ”¯æŒ(æ¨è)
pip install tensorboard
```

### 3. éªŒè¯æ–‡ä»¶ç»“æ„

```bash
# æ£€æŸ¥å…³é”®æ–‡ä»¶
ls marl_framework/mapping/frontier_detection.py  # Week 1
ls marl_framework/utils/coordination.py          # Week 2
ls marl_framework/utils/metrics.py               # Week 3
ls scripts/ablation_study.py                     # Week 4
ls scripts/benchmark_runner.py                   # Week 4
ls scripts/result_analyzer.py                    # Week 4
```

---

## å¿«é€Ÿæµ‹è¯•(æ¨èå…ˆè¿è¡Œ)

### Option 1: å•å…ƒæµ‹è¯•

```bash
# æµ‹è¯•frontieræ£€æµ‹
python -c "from marl_framework.mapping.frontier_detection import test_frontier_detector; test_frontier_detector()"

# æµ‹è¯•ååŒæœºåˆ¶
python -c "from marl_framework.utils.coordination import test_coordination_manager; test_coordination_manager()"

# æµ‹è¯•è¯„ä¼°æŒ‡æ ‡
python -c "from marl_framework.utils.metrics import test_metrics_system; test_metrics_system()"
```

### Option 2: é…ç½®éªŒè¯

```bash
# éªŒè¯æ¶ˆèå®éªŒé…ç½®ç”Ÿæˆ
python scripts/ablation_study.py --setup_only

# éªŒè¯åŸºå‡†æµ‹è¯•åœºæ™¯ç”Ÿæˆ
python scripts/benchmark_runner.py --setup_only
```

---

## å®éªŒæµç¨‹

### é˜¶æ®µ1: å°è§„æ¨¡æ¶ˆèå®éªŒ(æ¨èå¼€å§‹)

**ç›®æ ‡**: éªŒè¯æ¡†æ¶å¯ç”¨æ€§,å¿«é€Ÿè¿­ä»£

#### Step 1.1: è¿è¡Œ3ç»„å…³é”®å¯¹æ¯”å®éªŒ

```bash
# åªè¿è¡Œ3ç»„æœ€å…³é”®çš„å®éªŒ(çº¦3å°æ—¶)
python scripts/ablation_study.py \
    --base_config marl_framework/configs/params_advanced_search.yaml \
    --output_dir experiments/ablation_quick \
    --run_experiments intrinsic_baseline intrinsic_frontier intrinsic_full
```

**é¢„æœŸè¾“å‡º**:
```
experiments/ablation_quick/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ intrinsic_baseline.yaml
â”‚   â”œâ”€â”€ intrinsic_frontier.yaml
â”‚   â””â”€â”€ intrinsic_full.yaml
â””â”€â”€ logs/
    â”œâ”€â”€ intrinsic_baseline.log
    â”œâ”€â”€ intrinsic_frontier.log
    â””â”€â”€ intrinsic_full.log
```

#### Step 1.2: åˆ†æåˆæ­¥ç»“æœ

```bash
python scripts/result_analyzer.py \
    --log_dir experiments/ablation_quick/logs \
    --output_dir experiments/analysis_quick \
    --baseline intrinsic_baseline \
    --experiments intrinsic_baseline intrinsic_frontier intrinsic_full
```

**é¢„æœŸè¾“å‡º**:
```
experiments/analysis_quick/
â”œâ”€â”€ ablation_metrics.csv          # åŸå§‹æ•°æ®
â”œâ”€â”€ statistical_tests.csv         # ç»Ÿè®¡ç»“æœ
â””â”€â”€ plots/
    â”œâ”€â”€ ablation_discovery_rate.png
    â”œâ”€â”€ ablation_search_efficiency.png
    â””â”€â”€ learning_curves_reward.png
```

#### Step 1.3: æ£€æŸ¥ç»“æœ

```bash
# æŸ¥çœ‹ç»Ÿè®¡æ£€éªŒç»“æœ
cat experiments/analysis_quick/statistical_tests.csv

# æœŸæœ›: frontieræ˜¾è‘—ä¼˜äºbaseline (p < 0.05)
```

---

### é˜¶æ®µ2: å®Œæ•´æ¶ˆèå®éªŒ

**ç›®æ ‡**: ç³»ç»Ÿæ€§éªŒè¯æ‰€æœ‰ç»„ä»¶

#### Step 2.1: è¿è¡Œå®Œæ•´æ¶ˆèå®éªŒ(14ç»„)

```bash
# è¿è¡Œæ‰€æœ‰14ç»„æ¶ˆèå®éªŒ(çº¦14å°æ—¶)
python scripts/ablation_study.py \
    --base_config marl_framework/configs/params_advanced_search.yaml \
    --output_dir experiments/ablation_full
```

**å®éªŒç»„**:
- å†…åœ¨å¥–åŠ±: baseline, coverage, frontier, curiosity, full (5ç»„)
- ååŒæœºåˆ¶: baseline, overlap, division, collab, full (5ç»„)
- é€šä¿¡æ¡ä»¶: full_comm, limited, sparse, no_comm (4ç»„)

#### Step 2.2: å…¨é¢åˆ†æ

```bash
python scripts/result_analyzer.py \
    --log_dir experiments/ablation_full/logs \
    --output_dir experiments/analysis_full \
    --baseline intrinsic_baseline \
    --experiments intrinsic_baseline intrinsic_coverage intrinsic_frontier \
                 intrinsic_curiosity intrinsic_full \
                 coord_baseline coord_overlap coord_division coord_collab coord_full \
                 full_comm limited_comm sparse_comm no_comm
```

---

### é˜¶æ®µ3: åŸºå‡†æµ‹è¯•

**ç›®æ ‡**: å¤šåœºæ™¯éªŒè¯å’Œbaselineå¯¹æ¯”

#### Step 3.1: è¿è¡ŒåŸºå‡†æµ‹è¯•(12åœºæ™¯)

```bash
# å¹¶è¡Œè¿è¡Œ12ç»„åœºæ™¯æµ‹è¯•(çº¦6å°æ—¶,2 workers)
python scripts/benchmark_runner.py \
    --base_config marl_framework/configs/params_advanced_search.yaml \
    --output_dir experiments/benchmark \
    --max_workers 2
```

**åœºæ™¯**:
- è§„æ¨¡: small, medium, large, xlarge (4ç»„)
- å¯†åº¦: sparse, normal, dense, very_dense (4ç»„)
- å¤æ‚åº¦: simple, moderate, complex, extreme (4ç»„)

#### Step 3.2: Baselineå¯¹æ¯”

```bash
# å¦‚æœå·²ç»è¿è¡Œäº†åŸºå‡†æµ‹è¯•ä½†è·³è¿‡äº†baseline
# å¯ä»¥å•ç‹¬è¿è¡Œbaselineå¯¹æ¯”
python -c "
from scripts.benchmark_runner import BaselineComparator
import glob

scenarios = [f.stem for f in Path('experiments/benchmark/scenarios').glob('*.yaml')]
comparator = BaselineComparator(
    'experiments/benchmark/scenarios',
    'experiments/benchmark/baselines'
)
comparator.run_all_baselines(scenarios)
"
```

---

## ç›‘æ§å®éªŒè¿›åº¦

### TensorBoardç›‘æ§

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir=experiments/ablation_full/logs

# è®¿é—® http://localhost:6006
# æŸ¥çœ‹å®æ—¶è®­ç»ƒæ›²çº¿
```

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹æŸä¸ªå®éªŒçš„æ—¥å¿—
tail -f experiments/ablation_full/logs/intrinsic_frontier.log

# æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
grep -i error experiments/ablation_full/logs/*.log
```

---

## ç»“æœè§£è¯»

### å…³é”®æŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | å«ä¹‰ | æœŸæœ›å€¼ |
|------|------|--------|
| `discovery_rate` | ç›®æ ‡å‘ç°ç‡ | è¶Šé«˜è¶Šå¥½ (0-1) |
| `completion_time` | ä»»åŠ¡å®Œæˆæ—¶é—´ | è¶Šä½è¶Šå¥½ |
| `search_efficiency` | æœç´¢æ•ˆç‡ | è¶Šé«˜è¶Šå¥½ |
| `coordination_efficiency` | ååŒæ•ˆç‡ | è¶Šé«˜è¶Šå¥½ |
| `path_redundancy` | è·¯å¾„å†—ä½™åº¦ | è¶Šä½è¶Šå¥½ |
| `load_balance` | è´Ÿè½½å‡è¡¡ | è¶Šæ¥è¿‘1è¶Šå¥½ |

### æˆåŠŸæ ‡å‡†

âœ… **Frontier vs Baseline**:
- discovery_rateæå‡ > 10%
- search_efficiencyæå‡ > 15%
- p-value < 0.05, Cohen's d > 0.5

âœ… **å®Œæ•´ååŒ vs å•ä¸€æœºåˆ¶**:
- coordination_efficiencyæå‡ > 20%
- load_balanceæ”¹å–„ > 10%
- p-value < 0.05

âœ… **å¯æ‰©å±•æ€§**:
- æ€§èƒ½é€€åŒ– < 20% (agentsæ•°é‡ç¿»å€æ—¶)
- ä¿æŒæ˜¾è‘—ä¼˜äºbaseline

---

## å¸¸è§é—®é¢˜

### Q1: å®éªŒè¿è¡Œå¤±è´¥

```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶
python -c "import yaml; yaml.safe_load(open('marl_framework/configs/params_advanced_search.yaml'))"

# æ£€æŸ¥Pythonç¯å¢ƒ
python -c "import numpy, pandas, scipy; print('Dependencies OK')"

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯
cat experiments/ablation_full/logs/FAILED_EXPERIMENT.log
```

### Q2: å†…å­˜ä¸è¶³

```bash
# å‡å°‘å¹¶è¡Œworkeræ•°é‡
python scripts/benchmark_runner.py --max_workers 1

# æˆ–åˆ†æ‰¹è¿è¡Œ
python scripts/ablation_study.py --run_experiments intrinsic_baseline intrinsic_frontier
python scripts/ablation_study.py --run_experiments coord_baseline coord_full
```

### Q3: è®­ç»ƒæ—¶é—´è¿‡é•¿

```bash
# å‡å°‘è®­ç»ƒè½®æ•°(ä»…ç”¨äºå¿«é€Ÿæµ‹è¯•)
# ä¿®æ”¹ params_advanced_search.yaml:
# training:
#   num_episodes: 100  # åŸæ¥1000

# æˆ–åªåœ¨å°åœºæ™¯æµ‹è¯•
python scripts/benchmark_runner.py --run_experiments scale_small density_sparse
```

### Q4: TensorBoardæ—¥å¿—è§£æå¤±è´¥

```bash
# æ‰‹åŠ¨æ£€æŸ¥eventæ–‡ä»¶
ls experiments/ablation_full/logs/*/events.out.tfevents.*

# å¦‚æœç¼ºå¤±,è¯´æ˜å®éªŒå¯èƒ½æœªæ­£ç¡®è¿è¡Œ
# é‡æ–°è¿è¡Œè¯¥å®éªŒ
```

---

## ç”Ÿæˆè®ºæ–‡ç»“æœ

### 1. æå–å…³é”®æ•°æ®

```bash
# æ¶ˆèå®éªŒç»“æœè¡¨
python scripts/result_analyzer.py \
    --log_dir experiments/ablation_full/logs \
    --output_dir paper_results \
    --baseline intrinsic_baseline \
    --experiments intrinsic_baseline intrinsic_frontier intrinsic_full

# è¾“å‡º: paper_results/ablation_metrics.csv
# å¯ç›´æ¥å¯¼å…¥LaTeXè¡¨æ ¼
```

### 2. ç”Ÿæˆå›¾è¡¨

æ‰€æœ‰å›¾è¡¨å·²è‡ªåŠ¨ç”Ÿæˆåœ¨ `experiments/analysis_full/plots/`:
- `ablation_*.png`: æ¶ˆèå®éªŒå¯¹æ¯”(Figure 1-3)
- `learning_curves_*.png`: å­¦ä¹ æ›²çº¿(Figure 4)
- `performance_heatmap.png`: æ€§èƒ½çƒ­åŠ›å›¾(Figure 5)

### 3. ç»Ÿè®¡æ˜¾è‘—æ€§

```bash
# ç»Ÿè®¡æ£€éªŒç»“æœ
cat experiments/analysis_full/statistical_tests.csv

# åŒ…å«:
# - p-values (æ˜¾è‘—æ€§)
# - Cohen's d (æ•ˆåº”å¤§å°)
# - å‡å€¼å’Œæ ‡å‡†å·®
```

---

## ä¸‹ä¸€æ­¥

### å¦‚æœåˆæ­¥ç»“æœè‰¯å¥½:
1. âœ… è¿è¡Œå®Œæ•´æ¶ˆèå®éªŒ
2. âœ… è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•
3. âœ… ç”Ÿæˆæ‰€æœ‰å›¾è¡¨å’Œç»Ÿè®¡ç»“æœ
4. ğŸ“ å¼€å§‹æ’°å†™è®ºæ–‡å®éªŒç« èŠ‚

### å¦‚æœç»“æœä¸ç†æƒ³:
1. ğŸ”§ è°ƒæ•´è¶…å‚æ•° (params_advanced_search.yaml)
2. ğŸ”§ å¢åŠ è®­ç»ƒè½®æ•°
3. ğŸ”§ æ£€æŸ¥rewardè®¾è®¡
4. ğŸ”„ é‡æ–°è¿è¡Œå®éªŒ

### è®ºæ–‡å†™ä½œ:
- å‚è€ƒ `WEEK4_SUMMARY.md` ä¸­çš„è®ºæ–‡ç« èŠ‚ç»“æ„
- ä½¿ç”¨ç”Ÿæˆçš„å›¾è¡¨å’Œç»Ÿè®¡ç»“æœ
- å¼ºè°ƒfrontier-basedæ¢ç´¢å’ŒååŒæœºåˆ¶çš„åˆ›æ–°æ€§

---

## æ—¶é—´é¢„ä¼°

| ä»»åŠ¡ | æ—¶é—´ | è¯´æ˜ |
|------|------|------|
| å¿«é€Ÿæµ‹è¯• | 3 hours | 3ç»„å…³é”®å¯¹æ¯” |
| å®Œæ•´æ¶ˆèå®éªŒ | 14 hours | 14ç»„å®éªŒ |
| åŸºå‡†æµ‹è¯• | 6 hours | 12åœºæ™¯,2 workers |
| Baselineå¯¹æ¯” | 8 hours | 12åœºæ™¯Ã—3 baselines |
| ç»“æœåˆ†æ | 2 hours | ç»Ÿè®¡åˆ†æ+å¯è§†åŒ– |
| **æ€»è®¡** | **33 hours** | çº¦1.5å¤©(è¿ç»­è¿è¡Œ) |

**å»ºè®®**: ä½¿ç”¨æœåŠ¡å™¨æˆ–é«˜æ€§èƒ½å·¥ä½œç«™,å¼€å¯å¤šworkerå¹¶è¡Œè®­ç»ƒã€‚

---

## æ”¯æŒ

é‡åˆ°é—®é¢˜?
1. æŸ¥çœ‹ `WEEK4_SUMMARY.md` è¯¦ç»†æ–‡æ¡£
2. æ£€æŸ¥å„å‘¨çš„å®ç°æ€»ç»“ (FRONTIER_SUMMARY.md, COORDINATION_SUMMARY.md)
3. è¿è¡Œå•å…ƒæµ‹è¯•éªŒè¯å„æ¨¡å—

ç¥å®éªŒé¡ºåˆ©! ğŸš€
